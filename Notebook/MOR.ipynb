{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"# AWS Glue Studio Notebook\n",
				"##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"#### Optional: Run this cell to see available notebook commands (\"magics\").\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 12,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session c78fb162-241e-4e1b-b6e0-3a332def3078.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Current idle_timeout is 2880 minutes.\n",
						"idle_timeout has been set to 2880 minutes.\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session c78fb162-241e-4e1b-b6e0-3a332def3078.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Setting Glue version to: 4.0\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session c78fb162-241e-4e1b-b6e0-3a332def3078.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Previous worker type: G.1X\n",
						"Setting new worker type to: G.1X\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session c78fb162-241e-4e1b-b6e0-3a332def3078.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Previous number of workers: 5\n",
						"Setting new number of workers to: 5\n"
					]
				},
				{
					"name": "stderr",
					"output_type": "stream",
					"text": [
						"You are already connected to a glueetl session c78fb162-241e-4e1b-b6e0-3a332def3078.\n",
						"\n",
						"No change will be made to the current session that is set as glueetl. The session configuration change will apply to newly created sessions.\n"
					]
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"The following configurations have been updated: {'--conf': 'spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.sql.hive.convertMetastoreParquet=false', '--enable-glue-datacatalog': 'true', '--datalake-formats': 'hudi'}\n"
					]
				}
			],
			"source": [
				"\n",
				"%idle_timeout 2880\n",
				"%glue_version 4.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 5\n",
				"\n",
				"%%configure\n",
				"{\n",
				"    \"--conf\": \"spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.sql.hive.convertMetastoreParquet=false\",\n",
				"    \"--enable-glue-datacatalog\" :\"true\",\n",
				"    \"--datalake-formats\":\"hudi\"\n",
				"}"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"####  Run this cell to set up and start your interactive session.\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"\n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+---------+\n",
						"|namespace|\n",
						"+---------+\n",
						"|  default|\n",
						"|  hudidb1|\n",
						"|  hudidb2|\n",
						"|  hudidb3|\n",
						"+---------+\n"
					]
				}
			],
			"source": [
				"spark.sql(\"show databases;\").show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Some modules are missing No module named 'faker'\n"
					]
				}
			],
			"source": [
				"try:\n",
				"    import os\n",
				"    import sys\n",
				"\n",
				"\n",
				"    import pyspark\n",
				"    from pyspark import SparkConf, SparkContext\n",
				"    from pyspark.sql import SparkSession\n",
				"    from pyspark.sql.functions import col, asc, desc\n",
				"    from awsglue.utils import getResolvedOptions\n",
				"    from awsglue.dynamicframe import DynamicFrame\n",
				"    from awsglue.context import GlueContext\n",
				"\n",
				"    from faker import Faker\n",
				"\n",
				"    print(\"All modules are loaded .....\")\n",
				"\n",
				"except Exception as e:\n",
				"    print(\"Some modules are missing {} \".format(e))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 20,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"database_name1 = \"hudidb7\"\n",
				"table_name = \"hudi_table\"\n",
				"base_s3_path = \"s3a://test-ramneek-2\"\n",
				"final_base_path = \"{base_s3_path}/{table_name}\".format(\n",
				"    base_s3_path=base_s3_path, table_name=table_name\n",
				")"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 21,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"class DataGenerator(object):\n",
				"\n",
				"    @staticmethod\n",
				"    def get_data():\n",
				"        # Manually created data\n",
				"        return [\n",
				"            (1, \"Alice Johnson\", \"IT\", \"CA\", 120000, 30, 5000, 1677624870),\n",
				"            (2, \"Bob Smith\", \"HR\", \"NY\", 90000, 40, 7000, 1677624871),\n",
				"            (3, \"Charlie Lee\", \"Sales\", \"TX\", 110000, 35, 8000, 1677624872),\n",
				"            (4, \"David Brown\", \"Marketing\", \"FL\", 95000, 29, 4000, 1677624873),\n",
				"            (5, \"Eve Davis\", \"IT\", \"IL\", 105000, 32, 6000, 1677624874)\n",
				"        ]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 22,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"def create_spark_session():\n",
				"    spark = SparkSession \\\n",
				"        .builder \\\n",
				"        .config('spark.serializer', 'org.apache.spark.serializer.KryoSerializer') \\\n",
				"        .getOrCreate()\n",
				"    return spark\n",
				"\n",
				"\n",
				"spark = create_spark_session()\n",
				"sc = spark.sparkContext\n",
				"glueContext = GlueContext(sc)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 23,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"hudi_options = {\n",
				"    'hoodie.table.name': table_name,\n",
				"    \"hoodie.datasource.write.storage.type\": \"MERGE_ON_READ\",\n",
				"    'hoodie.datasource.write.recordkey.field': 'emp_id',\n",
				"    'hoodie.datasource.write.table.name': table_name,\n",
				"    'hoodie.datasource.write.operation': 'upsert',\n",
				"    'hoodie.datasource.write.precombine.field': 'ts',\n",
				"\n",
				"    'hoodie.datasource.hive_sync.enable': 'true',\n",
				"    \"hoodie.datasource.hive_sync.mode\":\"hms\",\n",
				"    'hoodie.datasource.hive_sync.sync_as_datasource': 'false',\n",
				"    'hoodie.datasource.hive_sync.database': database_name1,\n",
				"    'hoodie.datasource.hive_sync.table': table_name,\n",
				"    'hoodie.datasource.hive_sync.use_jdbc': 'false',\n",
				"    'hoodie.datasource.hive_sync.partition_extractor_class': 'org.apache.hudi.hive.MultiPartKeysValueExtractor',\n",
				"    'hoodie.datasource.write.hive_style_partitioning': 'true',\n",
				"\n",
				"}"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 24,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"data = DataGenerator.get_data()\n",
				"\n",
				"columns = [\"emp_id\", \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\", \"ts\"]\n",
				"df = spark.createDataFrame(data=data, schema=columns)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 25,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+------+-------------+----------+-----+------+---+-----+----------+\n",
						"|emp_id|employee_name|department|state|salary|age|bonus|        ts|\n",
						"+------+-------------+----------+-----+------+---+-----+----------+\n",
						"|     1|Alice Johnson|        IT|   CA|120000| 30| 5000|1677624870|\n",
						"|     2|    Bob Smith|        HR|   NY| 90000| 40| 7000|1677624871|\n",
						"|     3|  Charlie Lee|     Sales|   TX|110000| 35| 8000|1677624872|\n",
						"|     4|  David Brown| Marketing|   FL| 95000| 29| 4000|1677624873|\n",
						"|     5|    Eve Davis|        IT|   IL|105000| 32| 6000|1677624874|\n",
						"+------+-------------+----------+-----+------+---+-----+----------+\n"
					]
				}
			],
			"source": [
				"df.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 26,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"df.write.format(\"hudi\").options(**hudi_options).mode(\"overwrite\").save(final_base_path)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 27,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+---------+\n",
						"|namespace|\n",
						"+---------+\n",
						"|  default|\n",
						"|  hudidb1|\n",
						"|  hudidb2|\n",
						"|  hudidb3|\n",
						"|  hudidb7|\n",
						"+---------+\n"
					]
				}
			],
			"source": [
				"spark.sql(\"show databases;\").show()\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 28,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"++\n",
						"||\n",
						"++\n",
						"++\n"
					]
				}
			],
			"source": [
				"spark.sql(\"use hudidb7;\").show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 29,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+---------+-------------+-----------+\n",
						"|namespace|    tableName|isTemporary|\n",
						"+---------+-------------+-----------+\n",
						"|  hudidb7|hudi_table_ro|      false|\n",
						"|  hudidb7|hudi_table_rt|      false|\n",
						"+---------+-------------+-----------+\n"
					]
				}
			],
			"source": [
				"spark.sql(\"show tables;\").show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 30,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+-------------+----------+-----+------+---+-----+----------+\n",
						"|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|emp_id|employee_name|department|state|salary|age|bonus|        ts|\n",
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+-------------+----------+-----+------+---+-----+----------+\n",
						"|  20240927075321357|20240927075321357...|                 1|                      |25309ccf-dec5-4ae...|     1|Alice Johnson|        IT|   CA|120000| 30| 5000|1677624870|\n",
						"|  20240927075321357|20240927075321357...|                 5|                      |25309ccf-dec5-4ae...|     5|    Eve Davis|        IT|   IL|105000| 32| 6000|1677624874|\n",
						"|  20240927075321357|20240927075321357...|                 3|                      |25309ccf-dec5-4ae...|     3|  Charlie Lee|     Sales|   TX|110000| 35| 8000|1677624872|\n",
						"|  20240927075321357|20240927075321357...|                 2|                      |25309ccf-dec5-4ae...|     2|    Bob Smith|        HR|   NY| 90000| 40| 7000|1677624871|\n",
						"|  20240927075321357|20240927075321357...|                 4|                      |25309ccf-dec5-4ae...|     4|  David Brown| Marketing|   FL| 95000| 29| 4000|1677624873|\n",
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+-------------+----------+-----+------+---+-----+----------+\n"
					]
				}
			],
			"source": [
				"spark.sql(\"select * from hudi_table_rt;\").show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 32,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"s3_parquet_path = \"s3://test-ramneek-2/hudi_table/25309ccf-dec5-4ae1-8f39-f6391e564bcb-0_0-84-348_20240927075321357.parquet\"\n",
				"\n",
				"# Read the Parquet file\n",
				"df1 = spark.read.parquet(s3_parquet_path)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 33,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+-------------+----------+-----+------+---+-----+----------+\n",
						"|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|emp_id|employee_name|department|state|salary|age|bonus|        ts|\n",
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+-------------+----------+-----+------+---+-----+----------+\n",
						"|  20240927075321357|20240927075321357...|                 1|                      |25309ccf-dec5-4ae...|     1|Alice Johnson|        IT|   CA|120000| 30| 5000|1677624870|\n",
						"|  20240927075321357|20240927075321357...|                 5|                      |25309ccf-dec5-4ae...|     5|    Eve Davis|        IT|   IL|105000| 32| 6000|1677624874|\n",
						"|  20240927075321357|20240927075321357...|                 3|                      |25309ccf-dec5-4ae...|     3|  Charlie Lee|     Sales|   TX|110000| 35| 8000|1677624872|\n",
						"|  20240927075321357|20240927075321357...|                 2|                      |25309ccf-dec5-4ae...|     2|    Bob Smith|        HR|   NY| 90000| 40| 7000|1677624871|\n",
						"|  20240927075321357|20240927075321357...|                 4|                      |25309ccf-dec5-4ae...|     4|  David Brown| Marketing|   FL| 95000| 29| 4000|1677624873|\n",
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+-------------+----------+-----+------+---+-----+----------+\n"
					]
				}
			],
			"source": [
				"df1.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 34,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"impleDataUpd = [\n",
				"    (6, \"This is APPEND\", \"Sales\", \"RJ\", 81000, 30, 23000, 827307999),\n",
				"    (7, \"This is APPEND\", \"Engineering\", \"RJ\", 79000, 53, 15000, 1627694678),\n",
				"]\n",
				"\n",
				"columns = [\"emp_id\", \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\", \"ts\"]\n",
				"usr_up_df = spark.createDataFrame(data=impleDataUpd, schema=columns)\n",
				"usr_up_df.write.format(\"hudi\").options(**hudi_options).mode(\"append\").save(final_base_path)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 35,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+--------------+-----------+-----+------+---+-----+----------+\n",
						"|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|emp_id| employee_name| department|state|salary|age|bonus|        ts|\n",
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+--------------+-----------+-----+------+---+-----+----------+\n",
						"|  20240927075321357|20240927075321357...|                 1|                      |25309ccf-dec5-4ae...|     1| Alice Johnson|         IT|   CA|120000| 30| 5000|1677624870|\n",
						"|  20240927075321357|20240927075321357...|                 5|                      |25309ccf-dec5-4ae...|     5|     Eve Davis|         IT|   IL|105000| 32| 6000|1677624874|\n",
						"|  20240927075321357|20240927075321357...|                 3|                      |25309ccf-dec5-4ae...|     3|   Charlie Lee|      Sales|   TX|110000| 35| 8000|1677624872|\n",
						"|  20240927075321357|20240927075321357...|                 2|                      |25309ccf-dec5-4ae...|     2|     Bob Smith|         HR|   NY| 90000| 40| 7000|1677624871|\n",
						"|  20240927075321357|20240927075321357...|                 4|                      |25309ccf-dec5-4ae...|     4|   David Brown|  Marketing|   FL| 95000| 29| 4000|1677624873|\n",
						"|  20240927080316210|20240927080316210...|                 6|                      |25309ccf-dec5-4ae...|     6|This is APPEND|      Sales|   RJ| 81000| 30|23000| 827307999|\n",
						"|  20240927080316210|20240927080316210...|                 7|                      |25309ccf-dec5-4ae...|     7|This is APPEND|Engineering|   RJ| 79000| 53|15000|1627694678|\n",
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+--------------+-----------+-----+------+---+-----+----------+\n"
					]
				}
			],
			"source": [
				"###while we did append, one more parquet got created in s3, since it is only an append to the dataset, no delta log file is generated till this step\n",
				"\n",
				"#25309ccf-dec5-4ae1-8f39-f6391e564bcb-0_0-122-497_20240927080316210.parquet\n",
				"\n",
				"s3_parquet_path = \"s3://test-ramneek-2/hudi_table/25309ccf-dec5-4ae1-8f39-f6391e564bcb-0_0-122-497_20240927080316210.parquet\"\n",
				"\n",
				"# Read the Parquet file\n",
				"df2 = spark.read.parquet(s3_parquet_path)\n",
				"\n",
				"df2.show()"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 36,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"\n",
				"###update\n",
				"\n",
				"impleDataUpd = [\n",
				"    (3, \"this is update on data lake\", \"Sales\", \"RJ\", 81000, 30, 23000, 827307999),\n",
				"]\n",
				"columns = [\"emp_id\", \"employee_name\", \"department\", \"state\", \"salary\", \"age\", \"bonus\", \"ts\"]\n",
				"usr_up_df = spark.createDataFrame(data=impleDataUpd, schema=columns)\n",
				"usr_up_df.write.format(\"hudi\").options(**hudi_options).mode(\"append\").save(final_base_path)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"##after an update operation, no parquet file is generated, only one delta log file is generated. let;s view the real time table."
			]
		},
		{
			"cell_type": "code",
			"execution_count": 39,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+--------------------+-----------+-----+------+---+-----+----------+\n",
						"|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|emp_id|       employee_name| department|state|salary|age|bonus|        ts|\n",
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+--------------------+-----------+-----+------+---+-----+----------+\n",
						"|  20240927075321357|20240927075321357...|                 1|                      |25309ccf-dec5-4ae...|     1|       Alice Johnson|         IT|   CA|120000| 30| 5000|1677624870|\n",
						"|  20240927075321357|20240927075321357...|                 5|                      |25309ccf-dec5-4ae...|     5|           Eve Davis|         IT|   IL|105000| 32| 6000|1677624874|\n",
						"|  20240927080655269|20240927080655269...|                 3|                      |25309ccf-dec5-4ae...|     3|this is update on...|      Sales|   RJ| 81000| 30|23000| 827307999|\n",
						"|  20240927075321357|20240927075321357...|                 2|                      |25309ccf-dec5-4ae...|     2|           Bob Smith|         HR|   NY| 90000| 40| 7000|1677624871|\n",
						"|  20240927075321357|20240927075321357...|                 4|                      |25309ccf-dec5-4ae...|     4|         David Brown|  Marketing|   FL| 95000| 29| 4000|1677624873|\n",
						"|  20240927080316210|20240927080316210...|                 6|                      |25309ccf-dec5-4ae...|     6|      This is APPEND|      Sales|   RJ| 81000| 30|23000| 827307999|\n",
						"|  20240927080316210|20240927080316210...|                 7|                      |25309ccf-dec5-4ae...|     7|      This is APPEND|Engineering|   RJ| 79000| 53|15000|1627694678|\n",
						"|  20240927080655269|20240927080655269...|                 3|                      |25309ccf-dec5-4ae...|     3|this is update on...|      Sales|   RJ| 81000| 30|23000| 827307999|\n",
						"+-------------------+--------------------+------------------+----------------------+--------------------+------+--------------------+-----------+-----+------+---+-----+----------+\n"
					]
				}
			],
			"source": [
				"spark.sql(\"select * from hudi_table_rt;\").show()   ###we can see, there is update at emp_id=3 record"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
